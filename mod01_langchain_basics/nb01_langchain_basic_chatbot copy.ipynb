{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682c4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe84af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f93f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Not much! I'm just an AI, I don't have personal experiences or emotions, but I'm always here to help answer any questions you might have or chat with you about something interesting. How about you? How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 13, 'total_tokens': 65, 'completion_time': 0.034776204, 'prompt_time': 0.004547631, 'queue_time': 0.111739, 'total_time': 0.039323835}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ebe596ad-cea3-4f09-bdaa-7fc04de08251-0', usage_metadata={'input_tokens': 13, 'output_tokens': 52, 'total_tokens': 65})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model call\n",
    "\n",
    "model.invoke(\"Whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42416cbd",
   "metadata": {},
   "source": [
    "[Exercise] Play along. Give bigger and bigger prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2738af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my knowledge. I'm trained on a massive dataset of text from the internet and can generate human-like responses to a wide range of topics and questions.\\n\\nI'm here to help you with any questions or topics you'd like to discuss. I can provide information on various subjects, including science, history, entertainment, and more. I can also help with language-related tasks, such as language translation, grammar correction, and text summarization.\\n\\nFeel free to ask me anything, and I'll do my best to assist you!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 14, 'total_tokens': 167, 'completion_time': 0.103228315, 'prompt_time': 0.002659545, 'queue_time': 0.100112355, 'total_time': 0.10588786}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c0576bde-8691-4159-8566-b8b7990e2826-0', usage_metadata={'input_tokens': 14, 'output_tokens': 153, 'total_tokens': 167})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f4578d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a Python code that multiplies two matrices of arbitrary but compatible order. The code checks if the dimensions of the matrices are compatible for multiplication and throws an exception if they are not.\\n\\n```python\\ndef multiply_matrices(mat1, mat2):\\n    # Get the dimensions of the matrices\\n    rows_mat1 = len(mat1)\\n    cols_mat1 = len(mat1[0])\\n    rows_mat2 = len(mat2)\\n    cols_mat2 = len(mat2[0])\\n    \\n    # Check if the matrices are compatible for multiplication\\n    if cols_mat1 != rows_mat2:\\n        raise ValueError(\"Matrices are not compatible for multiplication\")\\n    \\n    # Create a result matrix filled with zeros\\n    result = [[0 for _ in range(cols_mat2)] for _ in range(rows_mat1)]\\n    \\n    # Multiply the matrices\\n    for i in range(rows_mat1):\\n        for j in range(cols_mat2):\\n            for k in range(cols_mat1):\\n                result[i][j] += mat1[i][k] * mat2[k][j]\\n    \\n    return result\\n\\n# Example usage:\\nmat1 = [[1, 2, 3], [4, 5, 6]]\\nmat2 = [[7, 8], [9, 10], [11, 12]]\\nprint(multiply_matrices(mat1, mat2))\\n```\\n\\nThis code first checks if the number of columns in the first matrix matches the number of rows in the second matrix. If they don\\'t match, it raises a `ValueError` exception. If they do match, it creates a result matrix filled with zeros and then multiplies the elements of the matrices according to the standard rules of matrix multiplication.\\n\\nNote that this code assumes that the input matrices are lists of lists, where each inner list represents a row in the matrix. For example, the matrix [[1, 2, 3], [4, 5, 6]] would be represented as a list `[[1, 2, 3], [4, 5, 6]]`.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 43, 'total_tokens': 469, 'completion_time': 0.288090915, 'prompt_time': 0.007483412, 'queue_time': 0.133206988, 'total_time': 0.295574327}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0ac102a2-b0b9-430a-8bf8-68f525f7ad99-0', usage_metadata={'input_tokens': 43, 'output_tokens': 426, 'total_tokens': 469})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"\"\" Write a python code which can multiply two matrix of arbitrary but compatible order. The code should throw exception if the matrix dimentsions are not compatible for multiplication             \n",
    "             \"\"\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c8c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python code that multiplies two matrices of arbitrary but compatible order. The code checks if the dimensions of the matrices are compatible for multiplication and throws an exception if they are not.\n",
      "\n",
      "```python\n",
      "def multiply_matrices(mat1, mat2):\n",
      "    # Get the dimensions of the matrices\n",
      "    rows_mat1 = len(mat1)\n",
      "    cols_mat1 = len(mat1[0])\n",
      "    rows_mat2 = len(mat2)\n",
      "    cols_mat2 = len(mat2[0])\n",
      "    \n",
      "    # Check if the matrices are compatible for multiplication\n",
      "    if cols_mat1 != rows_mat2:\n",
      "        raise ValueError(\"Matrices are not compatible for multiplication\")\n",
      "    \n",
      "    # Create a result matrix filled with zeros\n",
      "    result = [[0 for _ in range(cols_mat2)] for _ in range(rows_mat1)]\n",
      "    \n",
      "    # Multiply the matrices\n",
      "    for i in range(rows_mat1):\n",
      "        for j in range(cols_mat2):\n",
      "            for k in range(cols_mat1):\n",
      "                result[i][j] += mat1[i][k] * mat2[k][j]\n",
      "    \n",
      "    return result\n",
      "\n",
      "# Example usage:\n",
      "mat1 = [[1, 2, 3], [4, 5, 6]]\n",
      "mat2 = [[7, 8], [9, 10], [11, 12]]\n",
      "print(multiply_matrices(mat1, mat2))\n",
      "```\n",
      "\n",
      "This code first checks if the number of columns in the first matrix matches the number of rows in the second matrix. If they don't match, it raises a `ValueError` exception. If they do match, it creates a result matrix filled with zeros and then multiplies the elements of the matrices according to the standard rules of matrix multiplication.\n",
      "\n",
      "Note that this code assumes that the input matrices are lists of lists, where each inner list represents a row in the matrix. For example, the matrix [[1, 2, 3], [4, 5, 6]] would be represented as a list `[[1, 2, 3], [4, 5, 6]]`.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b215da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='নমস্কার! (Namaskar!)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 25, 'total_tokens': 41, 'completion_time': 0.010946544, 'prompt_time': 0.003398103, 'queue_time': 0.045286716, 'total_time': 0.014344647}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9855f583-6fc2-4df6-94d7-403ed99bc07c-0', usage_metadata={'input_tokens': 25, 'output_tokens': 16, 'total_tokens': 41})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoking to build a converstation style call\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Bengali\"), # try punjabi, or any other Indian language\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9efe5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Generate python code for given tasks\"),\n",
    "    HumanMessage(\"Find max of given n numbers\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d70ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python code snippet that finds the maximum of `n` numbers:\n",
      "```\n",
      "def find_max(n, numbers):\n",
      "    return max(numbers)\n",
      "\n",
      "# Example usage:\n",
      "n = int(input(\"Enter the number of numbers: \"))\n",
      "numbers = [int(x) for x in input(\"Enter the numbers separated by space: \").split()]\n",
      "max_value = find_max(n, numbers)\n",
      "print(\"Maximum value:\", max_value)\n",
      "```\n",
      "Here's how the code works:\n",
      "\n",
      "1. The `find_max` function takes two arguments: `n` (the number of numbers) and `numbers` (a list of numbers).\n",
      "2. The `max` function is used to find the maximum value in the `numbers` list.\n",
      "3. In the example usage, the user is prompted to enter the number of numbers (`n`) and then the numbers themselves (separated by spaces).\n",
      "4. The `find_max` function is called with `n` and `numbers` as arguments, and the maximum value is printed to the console.\n",
      "\n",
      "For example, if the user enters `3` and the numbers `10 20 30`, the output would be `Maximum value: 30`.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36098aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39caa649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|What| a| profound| and| complex| question|!\n",
      "\n",
      "|Def|ining| \"|life|\"| has| been| a| subject| of| debate| among| scientists|,| philosophers|,| and| scholars| for| centuries|.| There| is| no| single|,| universally| accepted| definition| of| life|,| but| here|'s| a| common| understanding|:\n",
      "\n",
      "|Life| is| the| condition| or| quality| that| distingu|ishes| living| organisms| from| non|-l|iving| things|.| It| is| characterized| by|:\n",
      "\n",
      "|1|.| **|Organization|**:| Living| organisms| are| composed| of| one| or| more| cells|,| which| are| organized| into| complex| structures|.\n",
      "|2|.| **|Met|abol|ism|**:| They| carry| out| various| chemical| reactions| to| sustain| themselves|,| such| as| the| breakdown| and| synthesis| of| nutrients|.\n",
      "|3|.| **|Home|ost|asis|**:| They| regulate| their| internal| environment| to| maintain| a| stable| balance|,| despite| changes| in| external| conditions|.\n",
      "|4|.| **|G|rowth| and| Development|**:| Living| organisms| grow|,| adapt|,| and| evolve| over| time|.\n",
      "|5|.| **|Response| to| Stim|uli|**:| They| can| react| to| their| environment|,| such| as| by| moving|,| sensing|,| or| feeding|.\n",
      "|6|.| **|Re|production|**:| They| produce| offspring| that| are| genetically| similar| to| themselves|.\n",
      "|7|.| **|Ev|olution|**:| Living| organisms| evolve| over| time| through| natural| selection|,| genetic| drift|,| mutation|,| and| gene| flow|.\n",
      "\n",
      "|Some| of| the| key| factors| that| distinguish| living| organisms| from| non|-l|iving| things| include|:\n",
      "\n",
      "|1|.| **|Complex|ity|**:| Living| organisms| are| composed| of| multiple| components| that| interact| with| each| other| to| form| a| functional| whole|.\n",
      "|2|.| **|Self|-|organization|**:| Living| systems| have| the| ability| to| self|-|organ|ize| and| adapt| to| changes| in| their| environment|.\n",
      "|3|.| **|Information| storage|**:| Living| organisms| store| and| transmit| genetic| information|,| which| influences| their| development| and| behavior|.\n",
      "|4|.| **|Energy| processing|**:| Living| organisms| convert| energy| from| one| form| to| another|,| such| as| from| light| to| chemical| energy|.\n",
      "\n",
      "|However|,| it|'s| worth| noting| that| there| are| still| many| open| questions| and| debates| about| the| definition| of| life|.| For| example|,| what| about| viruses|,| which| are| often| considered| to| be| at| the| boundary| between| living| and| non|-l|iving|?| Or| what| about| organisms| that| are| able| to| survive| in| extreme| environments|,| such| as| high| temperatures| or| high| pressures|?\n",
      "\n",
      "|Ultimately|,| the| definition| of| life| may| evolve| as| our| understanding| of| the| universe| and| the| natural| world| continues| to| grow|.||"
     ]
    }
   ],
   "source": [
    "# streaming example\n",
    "import time\n",
    "\n",
    "for token in model.stream(\"What is life?\"):\n",
    "    time.sleep(0.1)\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class discussion point: What is an LLM as a program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat496-monsoon2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
