{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682c4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1d276",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca18e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "prompt_template = \"\"\"Translate the given text in to the given language: \n",
    "Text: {text}\n",
    "Lang: {lang}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca177aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the given text in to the given language: \n",
      "Text: Who are you?\n",
      "Lang: hindi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(text = \"Who are you?\", lang=\"hindi\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f93f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à¤†à¤ª à¤•à¥Œà¤¨ à¤¹à¥ˆà¤‚? (Aap kaun hain?)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 56, 'total_tokens': 71, 'completion_time': 0.055621582, 'prompt_time': 0.01454976, 'queue_time': 0.04294077, 'total_time': 0.070171342}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--477daf2d-8ce1-4e6e-b0ad-e27c5a5f4759-0', usage_metadata={'input_tokens': 56, 'output_tokens': 15, 'total_tokens': 71})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model call\n",
    "\n",
    "response =  model.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044667ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¤†à¤ª à¤•à¥Œà¤¨ à¤¹à¥ˆà¤‚? (Aap kaun hain?)\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fd624",
   "metadata": {},
   "source": [
    "# Exercise: A RAG Prompt (Retreival Augmented Generation)\n",
    "\n",
    "https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959ec4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15482b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know Ajit's age. The provided context only mentions Ajit's place of residence, Greater Noida, but does not include any information about his age. I cannot determine Ajit's age based on the given context.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = \"Ajit lives in Greater Noida\", \n",
    "    question=\"How old is Ajit?\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise time:\n",
    "\n",
    "# Change the context to your liking\n",
    "# Ask relevanent question to your context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35ab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_context = \"\"\"Donald Trump's top economic adviser has warned that if India fails to curb its Russian crude trade, the US President will not ease his stance on Washington's punitive tariffs on Indian imports. US National Economic Council Director Kevin Hassett called trade negotiations with New Delhi \"complicated\", as he accused India of \"intransigence\" in opening its markets to American products. \n",
    "\n",
    "\"If the Indians don't budge, I don't think President Trump will,\" he said. The United States on Wednesday doubled tariffs on Indian goods to a staggering 50 per cent, the highest for any country other than Brazil. This includes a 25 per cent additional duty for India's purchase of Russian crude oil.\n",
    "\n",
    "Add NDTV As A Trusted Source\n",
    "\n",
    "\"Indian Intransigence\" ðŸ¤¯: US Economic Adviser - \"If the Indians Don't Budge, I Don't Think Trump Will Either\"\n",
    "\n",
    "Kevin Hassett seems to think that protecting India's rights and rejecting elements of an FTA that aren't mutually beneficial is INTRANSIGENT - simply India refusing toâ€¦ https://t.co/gBZ3C9DEFS pic.twitter.com/cnWGXmUwAP\n",
    "\n",
    "â€” RT_India (@RT_India_news) August 28, 2025\n",
    "Hassett said trade negotiations with India were \"complicated\", claiming part of it \"has been tied to the pressure we've been trying to put on Russia in order to secure a peace deal and save millions of lives. And then there's the Indian intransigence about opening their markets to our products.\"\n",
    "\n",
    "Linking India-US trade negotiations to a marathon, Hassett said talks require a long-term outlook and acceptance of \"ebbs and flows\" before New Delhi and Washington reach the final position.\n",
    "\n",
    "\n",
    "\"When you look at trade negotiations, one lesson we've all learnt is that you need to keep your eyes on the horizon and recognise that there are going to be ebbs and flows before we reach the final position,\" he said.\n",
    "\n",
    "Team Trump's Tariff Outlook\n",
    "The Trump adviser's remarks echoed US Treasury Secretary Scott Bessent's earlier comments, where he said high tariffs on India are \"not just over India's purchase of Russian oil\" but also due to the protracted nature of the ongoing trade deal talks.\n",
    "\n",
    "\"I'd thought we'd have a deal in May or June; that India could be one of the earliest deals. But they, kind of, tapped us along,\" Bessent told Fox Business on Wednesday. \n",
    "\n",
    "He claimed New Delhi had been \"a bit uncooperative\" during negotiations and said, \"This is a very complicated relationship.\"\n",
    "\n",
    "\"I do think India is the world's largest democracy, and the US is the world's largest economy. I think at the end of the day we will come together,\" he added.\n",
    "\n",
    "India's Stand\n",
    "India has asserted that it is prepared to stand firm against US pressure, with Prime Minister Narendra Modi vowing he would \"never compromise\" the interests of the country's farmers.\n",
    "\n",
    "The government estimates the tariffs will impact $48.2 billion worth of Indian exports to the US. Officials have warned that, though the immediate impact of new duties appears limited, the ripple effects on the economy pose challenges that must be addressed.\n",
    "\n",
    "The new duties could make shipments to the US commercially unviable, triggering job losses and slower economic growth, they said.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1b7af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three bullet points summarizing the given context:\n",
      "* The US has warned India that if it doesn't curb its Russian crude trade, President Trump won't ease his stance on punitive tariffs on Indian imports.\n",
      "* The US has doubled tariffs on Indian goods to 50%, citing India's \"intransigence\" in opening its markets to American products and its purchase of Russian crude oil.\n",
      "* India has stated it will stand firm against US pressure, with Prime Minister Narendra Modi vowing to protect the country's interests, despite the tariffs potentially impacting $48.2 billion worth of Indian exports to the US.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = news_context, \n",
    "    question=\"Summarize the given in three bullet points\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912495fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = news_context, \n",
    "    question=\"Summarize the given in three bullet points\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "\n",
    "# How to put \n",
    "# context = content of a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24aed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news_article.txt\", 'r') as file:\n",
    "    new_context_from_file = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac2442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article suggests that the US is pressuring India to curb its Russian crude trade, with the US National Economic Council Director warning that President Trump will not ease his stance on punitive tariffs if India does not comply. The US has doubled tariffs on Indian goods to 50%, which could impact $48.2 billion worth of Indian exports to the US. India has asserted that it will stand firm against US pressure, with Prime Minister Narendra Modi vowing to protect the country's interests.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    context = new_context_from_file, \n",
    "    question=\"Give a critical insight of this article\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "# Grab a book from https://www.gutenberg.org/ebooks/bookshelf/657\n",
    "# save it as a local text file.\n",
    "# pass that book content as context\n",
    "# Ask questions relevant to the book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e794ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"book.txt\", 'r') as file:\n",
    "    book_context = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141497"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3bd05f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book, \"A History of the Peninsular War, Vol. 3, Sep. 1809-Dec. 1810\", is about the Peninsular War, specifically the period between September 1809 and December 1810. It covers the central crisis of the war, including the arrival of the French in front of the Lines of Torres Vedras and their first short retreat. The book is written by Charles Oman and includes maps, illustrations, and appendices to support the historical account.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    context = book_context[:len(book_context)//40], \n",
    "    question=\"What is this book about?\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca643860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat496-monsoon2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
