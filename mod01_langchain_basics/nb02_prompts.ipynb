{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682c4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1d276",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca18e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "prompt_template = \"\"\"Translate the given text in to the given language: \n",
    "Text: {text}\n",
    "Lang: {lang}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca177aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the given text in to the given language: \n",
      "Text: Who are you?\n",
      "Lang: hindi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(text = \"Who are you?\", lang=\"hindi\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f93f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of the text \"Who are you?\" in Hindi is:\\n\\nकौन आप हैं? (Kaan aap hai?)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 31, 'total_tokens': 59, 'completion_time': 0.019048655, 'prompt_time': 0.004096113, 'queue_time': 0.237620418, 'total_time': 0.023144768}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_ec364e7642', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--58941519-51a4-416f-9d3a-65e3ef938099-0', usage_metadata={'input_tokens': 31, 'output_tokens': 28, 'total_tokens': 59})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model call\n",
    "\n",
    "response =  model.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044667ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of the text \"Who are you?\" in Hindi is:\n",
      "\n",
      "कौन आप हैं? (Kaan aap hai?)\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fd624",
   "metadata": {},
   "source": [
    "# Exercise: A RAG Prompt\n",
    "\n",
    "https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959ec4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15482b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajit lives in India, in the city of Greater Noida.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    context = \"Ajit lives in Greater Noida\", \n",
    "    question=\"In which country does Ajit live in?\"\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbd227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat496-monsoon2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
